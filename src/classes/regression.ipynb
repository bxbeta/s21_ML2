{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d34741",
   "metadata": {},
   "source": [
    "# Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "dd23732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b60138",
   "metadata": {},
   "source": [
    "# Модель 1 Аналитическое решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c1135533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.w = None\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        \"\"\"\n",
    "        фукнкция обучения - вычисляет параметры модели (веса) по данной выборке\n",
    "\n",
    "        Inputs:\n",
    "        X - матрица признаков\n",
    "        y - вектор ответов\n",
    "\n",
    "        Outputs:\n",
    "        self - модель\n",
    "        \"\"\"\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            ones_col = np.ones((X.shape[0], 1))\n",
    "            # добавляем вектор единиц в x, чтобы не занулить смещение w0 (байес)\n",
    "            X = np.hstack([ones_col, X])\n",
    "\n",
    "        if not np.isclose(np.linalg.det(X.T @ X), 0.0):\n",
    "            self.w = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        функция предсказания - предсказывает ответы модели по данной выборке\n",
    "\n",
    "        Inputs:\n",
    "        X - матрица признаков\n",
    "\n",
    "        Outputs:\n",
    "        y_pred - предсказания\n",
    "        \"\"\"\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            ones_col = np.ones((X.shape[0], 1))\n",
    "            X = np.hstack([ones_col, X])\n",
    "\n",
    "        y_pred = X @ self.w\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def get_weights(self):\n",
    "        ''' \n",
    "        фун-я возвращает веса модели\n",
    "        '''\n",
    "        return self.w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd2c9f4",
   "metadata": {},
   "source": [
    "## сравниваю модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1cb04cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем простой датасет с одним признаком\n",
    "n_objects = 100\n",
    "\n",
    "\n",
    "def linear_func(x): return 3.2 * x + 8\n",
    "\n",
    "\n",
    "X = np.linspace(-10, 10, n_objects)\n",
    "y = linear_func(X) + np.random.randn(n_objects) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4240cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8dbfda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = SimpleLinearRegression()\n",
    "original_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3819cfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8e65e466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.80750756,  -9.82139648,   6.23800356,  -5.96714047,\n",
       "        30.00591561,  -4.68238847, -20.0994125 ,  -5.32476447,\n",
       "        24.8669076 , -19.4570365 , -11.74852448,   3.66849955,\n",
       "        31.93304362, -18.1722845 ,  28.72116361, -10.46377248,\n",
       "        19.72789959, -11.10614848,   6.88037956, -18.8146605 ])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(X_train[:, np.newaxis], y_train)\n",
    "simple_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "adb6eee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.80750756,  -9.82139648,   6.23800356,  -5.96714047,\n",
       "        30.00591561,  -4.68238847, -20.0994125 ,  -5.32476447,\n",
       "        24.8669076 , -19.4570365 , -11.74852448,   3.66849955,\n",
       "        31.93304362, -18.1722845 ,  28.72116361, -10.46377248,\n",
       "        19.72789959, -11.10614848,   6.88037956, -18.8146605 ])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model.fit(X_train[:, np.newaxis], y_train)\n",
    "original_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a6569",
   "metadata": {},
   "source": [
    "# Модель 2 с SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "82faa66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDLinearRegression:\n",
    "    def __init__(self, fit_intercept: bool = True, learning_rate: float = 0.01, \n",
    "                n_iter: int = 1000, batch_size: int = 10, random_state: int = 21): \n",
    "        \n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iter \n",
    "        self.batch_size = batch_size \n",
    "        self.random_state = random_state\n",
    "        self.w = None\n",
    "        self.loss_history = [] \n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    def _add_intercept(self, X: np.ndarray): \n",
    "        ones_col = np.ones((X.shape[0], 1)) # добавляем вектор единиц в x, чтобы не занулить смещение w0 (байес)\n",
    "        X = np.hstack([ones_col, X])\n",
    "        \n",
    "        return X \n",
    "    \n",
    "    def _gradient(self, X_batch: np.ndarray, y_batch: np.ndarray): \n",
    "        \"\"\"\n",
    "        Вычисление градиентов MSE loss для батча\n",
    "        L = (1/n) * Σ(y_pred - y)^2\n",
    "        ∇L = (2/n) * X.T @ (y_pred - y_true) = (2/n) * X.T @ (X @ w - y)\n",
    "        \"\"\"\n",
    "        \n",
    "        n = X_batch.shape[0] \n",
    "        y_pred = X_batch @ self.w \n",
    "        error = y_pred - y_batch\n",
    "        \n",
    "        gradient = (2/n) * X_batch.T @ error # type: ignore\n",
    "        return gradient \n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray): \n",
    "        \"\"\"\n",
    "        Обучение модели методом стохастического градиентного спуска\n",
    "        \n",
    "        Параметры:\n",
    "        -----------\n",
    "        X : матрица признаков (n_samples, n_features)\n",
    "        y : вектор целевых значений (n_samples,)\n",
    "        \"\"\"\n",
    "        \n",
    "        X_train = X.copy() \n",
    "        y_train = y.copy().ravel()\n",
    "        \n",
    "        if self.fit_intercept: \n",
    "            X_train = self._add_intercept(X_train)\n",
    "            \n",
    "        n_samples, n_features = X_train.shape \n",
    "        self.w = self.rng.randn(n_features) * 0.01 \n",
    "        \n",
    "        for epoch in tqdm(range(self.n_iter), desc='Training'):\n",
    "            epoch_loss_sum = 0\n",
    "            batch_count = 0\n",
    "            \n",
    "            indices = np.arange(n_samples) \n",
    "            \n",
    "            for i in range(0, n_samples, self.batch_size): \n",
    "                batch_indices = indices[i:i + self.batch_size]\n",
    "                \n",
    "                if len(batch_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                X_batch = X_train[batch_indices]\n",
    "                y_batch = y_train[batch_indices]\n",
    "                \n",
    "                grad = self._gradient(X_batch, y_batch)\n",
    "                self.w = self.w - self.lr * grad\n",
    "                \n",
    "                y_pred_batch = X_batch @ self.w\n",
    "                batch_loss = np.mean((y_pred_batch - y_batch) ** 2)\n",
    "                \n",
    "                epoch_loss_sum += batch_loss\n",
    "                batch_count += 1\n",
    "                \n",
    "            if batch_count > 0:\n",
    "                epoch_avg_loss = epoch_loss_sum / batch_count\n",
    "                self.loss_history.append(epoch_avg_loss) \n",
    "            else: \n",
    "                self.loss_history.append(0.0)\n",
    "            \n",
    "                \n",
    "        return self \n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        функция предсказания - предсказывает ответы модели по данной выборке\n",
    "        \n",
    "        Inputs:\n",
    "        X - матрица признаков\n",
    "        \n",
    "        Outputs:\n",
    "        y_pred - предсказания\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.fit_intercept: \n",
    "            X = self._add_intercept(X)\n",
    "\n",
    "        return X @ self.w\n",
    "               \n",
    "    def get_weights(self):\n",
    "        return self.w    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac902a3",
   "metadata": {},
   "source": [
    "## проверка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "42ee850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = SGDLinearRegression(batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "281f067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141a3e0890b740e699b127246ddbb2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  8.94658481,  -8.92009611,   6.48221503,  -5.22354143,\n",
       "        29.27763551,  -3.99135654, -18.77757523,  -4.60744899,\n",
       "        24.34889594, -18.16148279, -10.76837344,   4.01784525,\n",
       "        31.12591284, -16.9292979 ,  28.04545062,  -9.53618855,\n",
       "        19.42015638, -10.152281  ,   7.09830747, -17.54539034])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model.fit(X_train[:, np.newaxis], y_train)\n",
    "sgd_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b98f5a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.80750756,  -9.82139648,   6.23800356,  -5.96714047,\n",
       "        30.00591561,  -4.68238847, -20.0994125 ,  -5.32476447,\n",
       "        24.8669076 , -19.4570365 , -11.74852448,   3.66849955,\n",
       "        31.93304362, -18.1722845 ,  28.72116361, -10.46377248,\n",
       "        19.72789959, -11.10614848,   6.88037956, -18.8146605 ])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a4ffe",
   "metadata": {},
   "source": [
    "# Модель 3 классический градиентный спуск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "58901f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassicalGDLinearRegression:\n",
    "    def __init__(self, fit_intercept: bool = True, learning_rate: float = 0.01, \n",
    "                n_iter: int = 1000, random_state: int = 21): \n",
    "        \n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iter \n",
    "        self.random_state = random_state\n",
    "        self.w = None\n",
    "        self.loss_history = [] \n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    def _add_intercept(self, X: np.ndarray): \n",
    "        ones_col = np.ones((X.shape[0], 1)) # добавляем вектор единиц в x, чтобы не занулить смещение w0 (байес)\n",
    "        X = np.hstack([ones_col, X])\n",
    "        \n",
    "        return X \n",
    "    \n",
    "    def _gradient(self, X: np.ndarray, y: np.ndarray): \n",
    "        \"\"\"\n",
    "        Вычисление градиентов MSE loss для всей выборки\n",
    "        L = (1/n) * Σ(y_pred - y)^2\n",
    "        ∇L = (2/n) * X.T @ (y_pred - y_true) = (2/n) * X.T @ (X @ w - y)\n",
    "        \"\"\"\n",
    "        \n",
    "        n = X.shape[0] \n",
    "        y_pred = X @ self.w \n",
    "        error = y_pred - y\n",
    "        \n",
    "        gradient = (2/n) * X.T @ error # type: ignore\n",
    "        return gradient \n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray): \n",
    "        \"\"\"\n",
    "        Обучение модели с помощью классического градиентного спуска\n",
    "        \n",
    "        Параметры:\n",
    "        -----------\n",
    "        X : матрица признаков (n_samples, n_features)\n",
    "        y : вектор целевых значений (n_samples,)\n",
    "        \"\"\"\n",
    "        eps = 1e-4\n",
    "        best_loss = 10_000\n",
    "        X_train = X.copy() \n",
    "        y_train = y.copy().ravel()\n",
    "        \n",
    "        if self.fit_intercept: \n",
    "            X_train = self._add_intercept(X_train)\n",
    "            \n",
    "        n_samples, n_features = X_train.shape \n",
    "        self.w = self.rng.randn(n_features) * 0.01 \n",
    "        \n",
    "        for epoch in tqdm(range(self.n_iter), desc='Training'):            \n",
    "            grad = self._gradient(X_train, y_train)\n",
    "            self.w = self.w - self.lr * grad\n",
    "            \n",
    "            y_pred_batch = X_train @ self.w\n",
    "            loss = np.mean((y_pred_batch - y_train) ** 2)\n",
    "            self.loss_history.append(loss)\n",
    "            \n",
    "            # if loss < best_loss - eps: \n",
    "            #     best_loss = loss\n",
    "            # else: \n",
    "            #     print(f\"Ранняя остановка (эпоха {epoch}): loss стабилизировался на {loss:.4f}\")\n",
    "            #     break\n",
    "                \n",
    "        return self \n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        \"\"\"\n",
    "        функция предсказания - предсказывает ответы модели по данной выборке\n",
    "        \n",
    "        Inputs:\n",
    "        X - матрица признаков\n",
    "        \n",
    "        Outputs:\n",
    "        y_pred - предсказания\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.fit_intercept: \n",
    "            X = self._add_intercept(X)\n",
    "\n",
    "        return X @ self.w\n",
    "               \n",
    "    def get_weights(self):\n",
    "        return self.w    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9146be0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae646c69621490ca9bdd6a7700414fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<__main__.ClassicalGDLinearRegression at 0x1688a96a0>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_model = ClassicalGDLinearRegression() \n",
    "gd_model.fit(X_train[:, np.newaxis], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5cb7eefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.02244614, 3.0496576 ])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d952c32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.84394356, 3.17976121])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "67434f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.84394355, 3.17976121])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa6020",
   "metadata": {},
   "source": [
    "# Фун-ии метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c122e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(y_true, y_pred): \n",
    "    y_mean = np.mean(y_true)\n",
    "    ss_res = np.sum((y_true - y_pred)**2)\n",
    "    ss_tot = np.sum((y_true - y_mean)**2) \n",
    "    \n",
    "    if ss_tot == 0: \n",
    "        return 0.0 \n",
    "    \n",
    "    return 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "97515f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred): \n",
    "    return np.mean(np.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7e6c2451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_true, y_pred): \n",
    "    return np.mean((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b24dbb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_true, y_pred): \n",
    "    return np.sqrt(np.mean((y_true - y_pred)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bf8e2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gd_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1fe40e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.9520543460531936), 0.9520543460531936)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2(y_test, y_pred), r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c779e230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(3.2040642586746144), 3.2040642586746144)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE(y_test, y_pred), mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d7fc49b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(4.243925454289967), np.float64(4.243925454289967))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "b73b2f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(18.010903261570306), 18.010903261570306)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, y_pred), mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413c69c4",
   "metadata": {},
   "source": [
    "# L2 - регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "208f9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeLinearRegression(SGDLinearRegression): \n",
    "    def __init__(self, fit_intercept: bool = True, learning_rate: float = 0.01, \n",
    "                 n_iter: int = 1000, batch_size: int = 10, random_state: int = 21, alpha: float = 0):\n",
    "        super().__init__(fit_intercept, learning_rate, n_iter, batch_size, random_state)\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def _gradient(self, X_batch: np.ndarray, y_batch: np.ndarray):\n",
    "        \"\"\"\n",
    "        Градиент с L2 регуляризацией\n",
    "        ∇L = (2/n) * X.T @ (X @ w - y) + 2 * alpha * w\n",
    "        \"\"\"\n",
    "        \n",
    "        n = X_batch.shape[0] \n",
    "        y_pred = X_batch @ self.w \n",
    "        error = y_pred - y_batch\n",
    "        \n",
    "        mse_grad = (2/n) * (X_batch.T @ error)\n",
    "        l2_grad = 2 * self.alpha * self.w # type: ignore\n",
    "        \n",
    "        if self.fit_intercept:\n",
    "            l2_grad[0] = 0  # смещение не штрафуем\n",
    "        \n",
    "        return mse_grad + l2_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f884ac",
   "metadata": {},
   "source": [
    "## Проверяю метрики модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3f5a6",
   "metadata": {},
   "source": [
    "на изначальных параметрах alpha и learning_rate ridge показывает очень плохие результаты в предсказаниях, нужно было поиграться с learning_rate и alpha для точного поподания "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "19035ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993a290f157641ebb44761d621169fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge_model = RidgeLinearRegression(alpha=0.0001, learning_rate=0.0001, batch_size=10, n_iter=3000)\n",
    "ridge_model.fit(X_train[:, np.newaxis], y_train)\n",
    "ridge_pred = ridge_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "edbd48ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18.09409484015761)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, ridge_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "0440e155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(18.01090324233241)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, original_model.predict(X_test[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55c883",
   "metadata": {},
   "source": [
    "# L1-регуляризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9f99603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LassoLinearRegression(SGDLinearRegression): \n",
    "    def __init__(self, fit_intercept: bool = True, learning_rate: float = 0.01, n_iter: int = 1000, \n",
    "                 batch_size: int = 10, random_state: int = 21, alpha: float = 0.1):\n",
    "        super().__init__(fit_intercept, learning_rate, n_iter, batch_size, random_state)\n",
    "        self.alpha = 0.1\n",
    "    \n",
    "    def _gradient(self, X_batch: np.ndarray, y_batch: np.ndarray):\n",
    "        \"\"\"\n",
    "        Градиент с L1 регуляризацией (субградиент)\n",
    "        ∇L = (2/n) * X.T @ (X @ w - y) + alpha * sign(w)\n",
    "        \"\"\"\n",
    "     \n",
    "        n = X_batch.shape[0] \n",
    "        y_pred = X_batch @ self.w \n",
    "        error = y_pred - y_batch \n",
    "        \n",
    "        mse_grad = (2/n) * X_batch.T @ error \n",
    "        l1_grad = self.alpha * np.sign(self.w)  # type: ignore\n",
    "        \n",
    "        if self.fit_intercept: \n",
    "            l1_grad[0] = 0 # смещение не штрафуем\n",
    "        \n",
    "        return mse_grad + l1_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62745163",
   "metadata": {},
   "source": [
    "## Проверяю метрики модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e90884",
   "metadata": {},
   "source": [
    "Тоже самое! Нужно посмотреть разные параметры! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "86a5097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac14815954d24f06b6ad1c5a466c975b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lasso_model = LassoLinearRegression(alpha=0.01, learning_rate=0.001, batch_size=10, n_iter=3000)\n",
    "lasso_model.fit(X_train[:, np.newaxis], y_train)\n",
    "lasso_pred = lasso_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "14c2f263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(18.011537301836743), np.float64(18.01090324233241))"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, lasso_pred), MSE(y_test, original_model.predict(X_test[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26d5175",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4cc2aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticNetLinearRegression(SGDLinearRegression): \n",
    "    def __init__(self, fit_intercept: bool = True, learning_rate: float = 0.01, \n",
    "                 n_iter: int = 1000, batch_size: int = 10, random_state: int = 21,\n",
    "                 alpha: float = 0.01, l1_ratio : float = 0.5):\n",
    "        super().__init__(fit_intercept, learning_rate, n_iter, batch_size, random_state)\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def _gradient(self, X_batch: np.ndarray, y_batch: np.ndarray):\n",
    "        \"\"\"\n",
    "        Градиент ElasticNet\n",
    "        ∇L = (2/n) * X.T @ (X @ w - y) + \n",
    "             alpha * l1_ratio * sign(w) + \n",
    "             alpha * (1 - l1_ratio) * w\n",
    "        \"\"\"\n",
    "        n = X_batch.shape[0] \n",
    "        y_pred = X_batch @ self.w \n",
    "        error = y_pred - y_batch\n",
    "        \n",
    "        mse_grad = (2/n) * (X_batch.T @ error) \n",
    "        \n",
    "        l1_grad = self.alpha * self.l1_ratio * np.sign(self.w) # type: ignore\n",
    "        l2_grad = self.alpha * (1 - self.l1_ratio) * self.w  # type: ignore\n",
    "        \n",
    "        if self.fit_intercept: \n",
    "            l1_grad[0] = 0 \n",
    "            l2_grad[0] = 0 \n",
    "            \n",
    "        return mse_grad + l1_grad + l2_grad\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0267cedd",
   "metadata": {},
   "source": [
    "## Проверка метрик моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "8ec4a41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5852095b9c141338a0fd8b405b1c682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elastic_model = ElasticNetLinearRegression(alpha=0.0001, learning_rate=0.0001, batch_size=10, n_iter=3000, l1_ratio=0.01)\n",
    "elastic_model.fit(X_train[:, np.newaxis], y_train)\n",
    "elastic_pred = elastic_model.predict(X_test[:, np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "9b4a644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(18.094022608552972), np.float64(18.01090324233241))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(y_test, elastic_pred), MSE(y_test, original_model.predict(X_test[:, np.newaxis]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
